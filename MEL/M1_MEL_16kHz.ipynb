{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M1_MEL_16kHz.ipynb","provenance":[{"file_id":"1zj5e4PHCJOTwUw-lW7gR7ZQZnwojp8D8","timestamp":1650560789215},{"file_id":"1WwUgO3h3ZHlXCa5S8T-WAkJSqWwVcNbp","timestamp":1650474591914}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"966f1ec340ff4d88be04ae570fa1f904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f35e9a8a1074956a52121b050f59ff7","IPY_MODEL_c1dd64ffbf1a43e39fa5a76fe56355ae","IPY_MODEL_5a95f449b02648fc8dc49d3e39f0e828"],"layout":"IPY_MODEL_afe3eabb2c98490ab807333cf2d32634"}},"3f35e9a8a1074956a52121b050f59ff7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce82909a6d294b948998fcbf61becec7","placeholder":"​","style":"IPY_MODEL_a71cbd44662f481eab2e1b34366c6a7d","value":"100%"}},"c1dd64ffbf1a43e39fa5a76fe56355ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f62bb854d784e0789af944d86bbabf6","max":2428923189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b95c38533f94405cb7787e1b43111f17","value":2428923189}},"5a95f449b02648fc8dc49d3e39f0e828":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89622dd7cd504ab29a9d8c16c2be1be2","placeholder":"​","style":"IPY_MODEL_793165f57c744faaaf02656a20816449","value":" 2.26G/2.26G [00:15&lt;00:00, 231MB/s]"}},"afe3eabb2c98490ab807333cf2d32634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce82909a6d294b948998fcbf61becec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a71cbd44662f481eab2e1b34366c6a7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f62bb854d784e0789af944d86bbabf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b95c38533f94405cb7787e1b43111f17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89622dd7cd504ab29a9d8c16c2be1be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"793165f57c744faaaf02656a20816449":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchaudio\n","import sys\n","\n","import matplotlib.pyplot as plt\n","import IPython.display as ipd\n","\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader,random_split,Dataset\n","from torchaudio.datasets import SPEECHCOMMANDS\n","import os\n","\n","\n","class SubsetSC(SPEECHCOMMANDS):\n","    def __init__(self,subset: str = None):\n","        super().__init__(\"./\", download=True)\n","\n","        def load_list(filename):\n","            filepath = os.path.join(self._path, filename)\n","            with open(filepath) as fileobj:\n","                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n","\n","        if subset == \"validation\":\n","            self._walker = load_list(\"validation_list.txt\")\n","        elif subset == \"testing\":\n","            self._walker = load_list(\"testing_list.txt\")\n","        elif subset == \"training\":\n","            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n","            excludes = set(excludes)\n","            self._walker = [w for w in self._walker if w not in excludes]\n","\n","# Create training and testing split of the data. We do not use validation in this tutorial.\n","train_set = SubsetSC(\"training\")\n","val_set = SubsetSC(\"validation\")\n","test_set = SubsetSC(\"testing\")\n","\n","waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"],"metadata":{"id":"RdyHldsW_GiH","executionInfo":{"status":"ok","timestamp":1650645708202,"user_tz":-120,"elapsed":112024,"user":{"displayName":"Miriam Martínez Izquierdo","userId":"08554729055381167812"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["966f1ec340ff4d88be04ae570fa1f904","3f35e9a8a1074956a52121b050f59ff7","c1dd64ffbf1a43e39fa5a76fe56355ae","5a95f449b02648fc8dc49d3e39f0e828","afe3eabb2c98490ab807333cf2d32634","ce82909a6d294b948998fcbf61becec7","a71cbd44662f481eab2e1b34366c6a7d","6f62bb854d784e0789af944d86bbabf6","b95c38533f94405cb7787e1b43111f17","89622dd7cd504ab29a9d8c16c2be1be2","793165f57c744faaaf02656a20816449"]},"outputId":"067b08d4-6056-477a-9a0a-ab8bdcd8db86"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/2.26G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"966f1ec340ff4d88be04ae570fa1f904"}},"metadata":{}}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B69sv9w2Xu4_","executionInfo":{"status":"ok","timestamp":1650645708205,"user_tz":-120,"elapsed":40,"user":{"displayName":"Miriam Martínez Izquierdo","userId":"08554729055381167812"}},"outputId":"6864d10a-54a5-4b6e-8afc-bb956d0df55e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["print(len(train_set))\n","print(len(test_set))\n","print(len(train_set)+len(test_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lfyr8aujBwbE","executionInfo":{"status":"ok","timestamp":1650645708209,"user_tz":-120,"elapsed":35,"user":{"displayName":"Miriam Martínez Izquierdo","userId":"08554729055381167812"}},"outputId":"ed8f655c-6c4c-44c2-8a5d-f1c35e761642"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["84843\n","11005\n","95848\n"]}]},{"cell_type":"code","source":["def label_to_index(word):\n","    # Return the position of the word in labels\n","    return torch.tensor(labels.index(word))\n","\n","\n","def index_to_label(index):\n","    # Return the word corresponding to the index in labels\n","    # This is the inverse of label_to_index\n","    return labels[index]"],"metadata":{"id":"YhOTQwnCXj1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = sorted(list(set(datapoint[2] for datapoint in train_set)))"],"metadata":{"id":"2R3FzqBKbjnL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MelSpectrogram(nn.Module):\n","    def __init__(self, n_mels = 40, sfr=16000):\n","        super(MelSpectrogram, self).__init__()\n","        self.sfr = sfr\n","        self.window_stride=0.01\n","        self.window_size=0.02\n","        self.n_fft=512\n","        self.n_mels=n_mels\n","        \n","        self.win_length = int(self.sfr * self.window_size)\n","        self.hop_length = int(self.sfr * self.window_stride)\n","        self.lowfreq = 20\n","        self.highfreq = self.sfr/2 - 400\n","        self.window = torch.hamming_window(self.win_length).cuda()\n","  \n","        self.mel = torchaudio.transforms.MelSpectrogram(sample_rate=self.sfr, n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length, n_mels=self.n_mels)\n","        self.norm = nn.InstanceNorm2d(1)\n","\n","    def __call__(self, x):\n","        x = x.squeeze(1)\n","        x = self.mel(x)\n","        x = torch.log(x+0.0001)\n","        x = x.unsqueeze(1)\n","        return x"],"metadata":{"id":"ehHewGPTQKe1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad_sequence(batch):\n","    # Make all tensor in a batch the same length by padding with zeros\n","    batch = [item.t() for item in batch]\n","    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n","    return batch.permute(0, 2, 1)\n","\n","\n","def collate_fn(batch):\n","\n","    # A data tuple has the form:\n","    # waveform, sample_rate, label, speaker_id, utterance_number\n","\n","    tensors, targets = [], []\n","\n","    # Gather in lists, and encode labels as indices\n","    for waveform, _, label, *_ in batch:\n","        tensors += [waveform]\n","        targets += [label_to_index(label)]\n","\n","    # Group the list of tensors into a batched tensor\n","    tensors = pad_sequence(tensors)\n","    targets = torch.stack(targets)\n","\n","    mel_transform = nn.Sequential(\n","        MelSpectrogram()\n","    )\n","\n","    tensors = mel_transform(tensors)\n","\n","    return tensors, targets\n","\n","\n","batch_size = 256\n","\n","if device == \"cuda\":\n","    num_workers = 1\n","    pin_memory = True\n","else:\n","    num_workers = 0\n","    pin_memory = False\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_set,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    num_workers=num_workers,\n","    pin_memory=pin_memory,\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    val_set,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    num_workers=num_workers,\n","    pin_memory=pin_memory,\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_set,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=False,\n","    collate_fn=collate_fn,\n","    num_workers=num_workers,\n","    pin_memory=pin_memory,\n",")"],"metadata":{"id":"cFQPwoZiXn3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class M5(nn.Module):\n","    def __init__(self, num_class):\n","        super(M5,self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1)\n","        self.dropout1 = nn.Dropout(0.5) \n","    \n","        self.conv2 = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1)\n","        self.dropout2 = nn.Dropout(0.5)\n","\n","        self.fc1 = nn.Linear(1024, 256)\n","        #self.dropout5 = nn.Dropout(0.3)\n","        self.fc2 = nn.Linear(256,128)\n","        #self.dropout6 = nn.Dropout(0.3)\n","        self.fc3 = nn.Linear(128, num_class)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=3)\n","        x = self.dropout1(x)\n","        \n","        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=3)\n","        x = self.dropout2(x)\n","\n","        x = F.relu(self.fc1(x.reshape(-1,x.shape[1] * x.shape[2]*x.shape[3])))\n","        #x = self.dropout5(x)\n","        \n","        x = F.relu(self.fc2(x))\n","        #x = self.dropout6(x)\n","        \n","        x = self.fc3(x)\n","        \n","        return x \n","\n","\n","model = M5(num_class=35)\n","model.to(device)\n","print(model)\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","n = count_parameters(model)\n","print(\"Number of parameters: %s\" % n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtgJ7p18bdS0","executionInfo":{"status":"ok","timestamp":1650646915958,"user_tz":-120,"elapsed":351,"user":{"displayName":"Miriam Martínez Izquierdo","userId":"08554729055381167812"}},"outputId":"1672355f-204d-432a-dda7-b5e3ffd9d699"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["M5(\n","  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n","  (dropout1): Dropout(p=0.5, inplace=False)\n","  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n","  (dropout2): Dropout(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=35, bias=True)\n",")\n","Number of parameters: 301059\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n","#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n","scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01,\n","                                              steps_per_epoch=int(len(train_loader)),\n","                                              epochs=5,\n","                                              anneal_strategy='linear') "],"metadata":{"id":"8f6XtgxwecTB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(epoch, log_interval):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","\n","        data = data.to(device)\n","        target = target.to(device)\n","\n","        output = model(data)\n","\n","        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n","        #loss = F.nll_loss(output.squeeze(), target)\n","\n","        loss = F.cross_entropy(output.squeeze(), target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print training stats\n","        if batch_idx % log_interval == 0:\n","            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n","\n","        # record loss\n","        losses.append(loss.item())"],"metadata":{"id":"fbYIBXXTeeZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def number_of_correct(pred, target):\n","    # count number of correct predictions\n","    return pred.squeeze().eq(target).sum().item()\n","\n","\n","def get_likely_index(tensor):\n","    # find most likely label index for each element in the batch\n","    return tensor.argmax(dim=-1)\n","\n","@torch.no_grad()\n","def evaluate(data_source):\n","    model.eval()\n","    total_loss = 0.\n","    correct = 0\n","    n = 0\n","    for data, target in data_source:\n","\n","        data = data.to(device)\n","        target = target.to(device)\n","\n","        output = model(data)\n","\n","        #total_loss += target.numel() * F.nll_loss(output.squeeze(), target).item()\n","        total_loss += target.numel() * F.cross_entropy(output.squeeze(), target).item()\n","        n += target.numel()\n","\n","\n","        pred = get_likely_index(output)\n","        correct += number_of_correct(pred, target)\n","\n","        #print(pred)\n","        #print(target)\n","    \n","\n","    accuracy = 100 * correct / len(test_loader.dataset)\n","    \n","    return total_loss / n, accuracy"],"metadata":{"id":"TVF2dlELehIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_loss = float(\"inf\")\n","losses = []\n","\n","log_interval = 100\n","n_epoch = 10\n","\n","\n","for epoch in range(1, n_epoch+1):\n","    train(epoch, log_interval)\n","    val_loss, val_acc = evaluate(val_loader)\n","\n","    print(f'| Validation | val loss {val_loss:5.2f} | val accuracy {val_acc:.0f}%')\n","\n","    if val_loss < best_val_loss:\n","      with open(\"M1_MEL_16kHz.pth\", 'wb') as f:\n","        torch.save(model, f)\n","      best_val_loss = val_loss\n","    scheduler.step()\n","\n","with open(\"M1_MEL_16kHz.pth\", 'rb') as f:\n","  model = torch.load(f)\n","\n","with torch.no_grad():\n","  test_loss, test_acc = evaluate(test_loader)\n","    \n","print('=' * 89)\n","print(f'| End of training | test loss {test_loss:5.2f} | test accuracy {test_acc:.0f}%')\n","print('=' * 89)\n","\n","# Let's plot the training loss versus the number of iteration.\n","plt.plot(losses)\n","plt.title(\"training loss\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"oCXWvHPzelsv","executionInfo":{"status":"error","timestamp":1650647453684,"user_tz":-120,"elapsed":623,"user":{"displayName":"Miriam Martínez Izquierdo","userId":"08554729055381167812"}},"outputId":"8c725151-eec1-426a-9e83-931f76e147f1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-a8d5e154324c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-689407412bde>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_interval)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-457da99725bc>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     mel_transform = nn.Sequential(\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mMelSpectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-6331b3a9d1c1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_mels, sfr)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhighfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMelSpectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"]}]}]}
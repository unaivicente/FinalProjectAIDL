{"cells":[{"cell_type":"markdown","source":["# GRU-3\n","\n","## Hyperparameter tuning\n","\n","- Hidden dimension : 128\n","\n","- Loss function : Cross Entropy Loss\n","\n","- Training epochs : 10\n","\n","- Batch size : 100\n","\n","- Learning rate : 0.5\n","\n","- Optimizer : SGD"],"metadata":{"id":"QO7od4sLc-Y5"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"P1fXVpAVfevt","executionInfo":{"status":"ok","timestamp":1650733277016,"user_tz":-120,"elapsed":6880,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchaudio\n","import sys\n","\n","import numpy as np\n","\n","import math\n","\n","import matplotlib.pyplot as plt\n","import IPython.display as ipd\n","\n","from tqdm import tqdm\n","\n","from torchaudio.datasets import SPEECHCOMMANDS\n","import os"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkikOxvXiM5M","executionInfo":{"status":"ok","timestamp":1650733277018,"user_tz":-120,"elapsed":23,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}},"outputId":"cddd8759-3b0a-424a-cb4e-b082badbf78b"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Oa227SafiPoW","executionInfo":{"status":"ok","timestamp":1650733277397,"user_tz":-120,"elapsed":388,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["class SubsetSC(SPEECHCOMMANDS):\n","    def __init__(self, subset: str = None):\n","        super().__init__(\"./\", download=True)\n","\n","        def load_list(filename):\n","            filepath = os.path.join(self._path, filename)\n","            with open(filepath) as fileobj:\n","                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n","\n","        if subset == \"validation\":\n","            self._walker = load_list(\"validation_list.txt\")\n","        elif subset == \"testing\":\n","            self._walker = load_list(\"testing_list.txt\")\n","        elif subset == \"training\":\n","            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n","            excludes = set(excludes)\n","            self._walker = [w for w in self._walker if w not in excludes]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["af684e42f35545dab16d693fb62d343e","cb0deed2a6bf424fa7545ed09ce113cf","839ce186c0ca4d1992b9b80627db53e2","7256fd2a143b4ed68d18c5cc15b74068","55ca266681534690aeb73f4d7f72efd0","b93ba584c9b8441b82ff8da8f2b422ab","0614051f8c0045779af12ebb6f784f0c","46e9cfac265e49a8a77ca1b113cbf55b","724dd7de3612413ab945d1ba533cdb54","54ef7b5f0ca545bfa2db001b8553c4c5","054bcd4fd74b4f3ab707d295222ded85"]},"id":"bTGbXktIiRy5","outputId":"6db820c6-23bf-444c-c8cf-7508992d5326","executionInfo":{"status":"ok","timestamp":1650733359055,"user_tz":-120,"elapsed":81675,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/2.26G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af684e42f35545dab16d693fb62d343e"}},"metadata":{}}],"source":["# Create training and testing split of the data. We do not use validation in this tutorial.\n","train_set = SubsetSC(\"training\")\n","val_set = SubsetSC(\"validation\")\n","test_set = SubsetSC(\"testing\")\n","\n","waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"uXSkhxzuiTO4","executionInfo":{"status":"ok","timestamp":1650733376837,"user_tz":-120,"elapsed":17818,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["labels = sorted(list(set(datapoint[2] for datapoint in train_set)))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-TtKgOvZiVH1","executionInfo":{"status":"ok","timestamp":1650733376838,"user_tz":-120,"elapsed":7,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["new_sample_rate = 8000\n","transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n","transformed = transform(waveform)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"sb6IEUAkiWi7","executionInfo":{"status":"ok","timestamp":1650733376838,"user_tz":-120,"elapsed":5,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["def label_to_index(word):\n","    # Return the position of the word in labels\n","    return torch.tensor(labels.index(word))\n","\n","\n","def index_to_label(index):\n","    # Return the word corresponding to the index in labels\n","    # This is the inverse of label_to_index\n","    return labels[index]\n","\n","\n","word_start = \"yes\"\n","index = label_to_index(word_start)\n","word_recovered = index_to_label(index)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"r32fJfVkiYSe","executionInfo":{"status":"ok","timestamp":1650733377191,"user_tz":-120,"elapsed":14,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["def pad_sequence(batch):\n","    # Make all tensor in a batch the same length by padding with zeros\n","    batch = [item.t() for item in batch]\n","    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n","    return batch.permute(0, 2, 1)\n","\n","\n","def collate_fn(batch):\n","\n","    # A data tuple has the form:\n","    # waveform, sample_rate, label, speaker_id, utterance_number\n","\n","    tensors, targets = [], []\n","\n","    # Gather in lists, and encode labels as indices\n","    for waveform, _, label, *_ in batch:\n","        tensors += [waveform]\n","        targets += [label_to_index(label)]\n","\n","    # Group the list of tensors into a batched tensor\n","    tensors = pad_sequence(tensors)\n","    targets = torch.stack(targets)\n","\n","    return tensors, targets\n","\n","\n","batch_size = 100\n","\n","if device == \"cuda\":\n","    num_workers = 1\n","    pin_memory = True\n","else:\n","    num_workers = 0\n","    pin_memory = False\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_set,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    num_workers=num_workers,\n","    pin_memory=pin_memory,\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    val_set,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n","    num_workers=num_workers,\n","    pin_memory=pin_memory\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_set,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=False,\n","    collate_fn=collate_fn,\n","    num_workers=num_workers,\n","    pin_memory=pin_memory,\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"BKuz14-SibWt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650733386995,"user_tz":-120,"elapsed":9817,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}},"outputId":"0d72fb6f-e247-43d7-aeb4-2101b4f88ec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of parameters: 463907\n"]}],"source":["class GRU_3(nn.Module):\n","    def __init__(self, n_input=1, n_output=35, stride=3, hidden_dim=256, n_channel=128, nhead=4, num_layer=6):\n","        super().__init__()\n","        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n","        self.bn1 = nn.BatchNorm1d(n_channel)\n","        self.pool1 = nn.MaxPool1d(4)\n","        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n","        self.bn2 = nn.BatchNorm1d(n_channel)\n","        self.pool2 = nn.MaxPool1d(4)\n","        self.GRU = nn.GRU(2 * n_channel, hidden_dim, batch_first=True)\n","        self.fc1 = nn.Linear(hidden_dim, n_output)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(self.bn1(x))\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = F.relu(self.bn2(x))\n","        x = self.pool2(x)\n","        x = x.permute(0, 2, 1)\n","        x, hnn = self.GRU(x)\n","        return self.fc1(hnn[-1])\n","        #return F.log_softmax(x, dim=-1)\n","\n","model = GRU_3(n_input=transformed.shape[0], n_output=len(labels))\n","model.cuda()\n","#print(model)\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","n = count_parameters(model)\n","print(\"Number of parameters: %s\" % n)"]},{"cell_type":"code","source":["lr = 0.5"],"metadata":{"id":"81AcoP1K1wqH","executionInfo":{"status":"ok","timestamp":1650733386997,"user_tz":-120,"elapsed":22,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"sHSMT4RwigeC","executionInfo":{"status":"ok","timestamp":1650733386998,"user_tz":-120,"elapsed":19,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=0.0)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"]},{"cell_type":"code","source":["loss_f = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"x68SjnrNHP76","executionInfo":{"status":"ok","timestamp":1650733387000,"user_tz":-120,"elapsed":19,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"8eywGFApii0y","executionInfo":{"status":"ok","timestamp":1650733387001,"user_tz":-120,"elapsed":18,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["def train(epoch, log_interval):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","\n","        #data = data.to(device)\n","        #target = target.to(device)\n","\n","        data = data.cuda()\n","        target = target.cuda()\n","\n","        # apply transform and model on whole batch directly on device\n","        data = transform(data)\n","        output = model(data)\n","\n","        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n","        #loss = F.nll_loss(output.squeeze(), target)\n","        loss = loss_f(output.squeeze(), target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print training stats\n","        if batch_idx % log_interval == 0:\n","            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n","\n","        # record loss\n","        losses.append(loss.item())\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9RCUpCPCijwv","executionInfo":{"status":"ok","timestamp":1650733387002,"user_tz":-120,"elapsed":18,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}}},"outputs":[],"source":["def number_of_correct(pred, target):\n","    # count number of correct predictions\n","    return pred.squeeze().eq(target).sum().item()\n","\n","\n","def get_likely_index(tensor):\n","    # find most likely label index for each element in the batch\n","    return tensor.argmax(dim=-1)\n","\n","\n","@torch.no_grad()\n","def evaluate(data_source):\n","    model.eval()\n","    total_loss = 0.\n","    correct = 0\n","    n = 0\n","    for data, target in data_source:\n","\n","        data = data.to(device)\n","        target = target.to(device)\n","\n","        # apply transform and model on whole batch directly on device\n","        data = transform(data)\n","        output = model(data)\n","\n","        #total_loss += target.numel() * F.nll_loss(output.squeeze(), target).item()\n","        total_loss += target.numel() * loss_f(output.squeeze(), target).item()\n","        n += target.numel()\n","\n","        pred = get_likely_index(output)\n","        correct += number_of_correct(pred, target)\n","    \n"," \n","    accuracy = 100 * correct / len(test_loader.dataset)\n","    \n","    return total_loss / n, accuracy"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"DWRFYunhimLb","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1650733387797,"user_tz":-120,"elapsed":812,"user":{"displayName":"Miriam Martínez","userId":"00485205967731265435"}},"outputId":"63c66548-89ea-4880-9612-6794f514e6b7"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-af615bfb6604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-cc0f4326a688>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, log_interval)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# apply transform and model on whole batch directly on device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# negative log-likelihood for a tensor of size (batch x 1 x n_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-5311a77068c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#return F.log_softmax(x, dim=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise RuntimeError(\n\u001b[1;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 207\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 256, got 128"]}],"source":["best_val_loss = float(\"inf\")\n","losses = []\n","\n","log_interval = 100\n","n_epoch = 10\n","\n","\n","#The transform needs to live on the same device as the model and the data.\n","transform = transform.to(device)\n","\n","for epoch in range(1, n_epoch + 1):\n","    train(epoch, log_interval)\n","    val_loss, val_acc = evaluate(val_loader)\n","\n","    print(f'| Validation | val loss {val_loss:5.2f} | val accuracy {val_acc:.0f}%')\n","\n","    if val_loss < best_val_loss:\n","      with open(\"GRU-3_8kHz.pth\", 'wb') as f:\n","        torch.save(model, f)\n","      best_val_loss = val_loss\n","    \n","    scheduler.step()\n","    lr = scheduler.get_last_lr()[0]\n","\n","with open(\"GRU-3_8kHz.pth\", 'rb') as f:\n","  model = torch.load(f)\n","\n","with torch.no_grad():\n","  test_loss, test_acc = evaluate(test_loader)\n","\n","print('=' * 89)\n","print(f'| End of training | test loss {test_loss:5.2f} | test accuracy {test_acc:.0f}%')\n","print('=' * 89)\n","\n","# Let's plot the training loss versus the number of iteration.\n","plt.plot(losses)\n","plt.title(\"training loss\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"Copy of GRU-3_8kHz.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"af684e42f35545dab16d693fb62d343e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb0deed2a6bf424fa7545ed09ce113cf","IPY_MODEL_839ce186c0ca4d1992b9b80627db53e2","IPY_MODEL_7256fd2a143b4ed68d18c5cc15b74068"],"layout":"IPY_MODEL_55ca266681534690aeb73f4d7f72efd0"}},"cb0deed2a6bf424fa7545ed09ce113cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b93ba584c9b8441b82ff8da8f2b422ab","placeholder":"​","style":"IPY_MODEL_0614051f8c0045779af12ebb6f784f0c","value":"100%"}},"839ce186c0ca4d1992b9b80627db53e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46e9cfac265e49a8a77ca1b113cbf55b","max":2428923189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_724dd7de3612413ab945d1ba533cdb54","value":2428923189}},"7256fd2a143b4ed68d18c5cc15b74068":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54ef7b5f0ca545bfa2db001b8553c4c5","placeholder":"​","style":"IPY_MODEL_054bcd4fd74b4f3ab707d295222ded85","value":" 2.26G/2.26G [00:11&lt;00:00, 268MB/s]"}},"55ca266681534690aeb73f4d7f72efd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93ba584c9b8441b82ff8da8f2b422ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0614051f8c0045779af12ebb6f784f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46e9cfac265e49a8a77ca1b113cbf55b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"724dd7de3612413ab945d1ba533cdb54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54ef7b5f0ca545bfa2db001b8553c4c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"054bcd4fd74b4f3ab707d295222ded85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}